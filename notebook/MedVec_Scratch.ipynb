{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU1XDpuS5nfx"
      },
      "source": [
        "# MedVec-Scratch\n",
        "\n",
        "![MedVec-Architecture](https://raw.githubusercontent.com/Vivek02Sharma/MedVec-Scratch/main/assets/MedVec-scratch.png)\n",
        "\n",
        "\n",
        "Dataset_URL - https://huggingface.co/datasets/abhinand/MedEmbed-training-triplets-v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PGAqoEKI5bvw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import math\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au29hEST-sac"
      },
      "source": [
        "## Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yplFKgVk9v4U"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model, max_len = 5000):\n",
        "    super().__init__()\n",
        "    pe = torch.zeros(max_len, d_model, dtype = torch.float32)\n",
        "    pos = torch.arange(0, max_len, dtype = torch.float32).unsqueeze(1)\n",
        "    denominators = torch.exp(torch.arange(0, d_model, 2, dtype = torch.float32) * (-math.log(10000.0)/d_model))\n",
        "    pe[:, 0::2] = torch.sin(pos * denominators)\n",
        "    pe[:, 1::2] = torch.cos(pos * denominators)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    seq_len = x.size(1)\n",
        "    x = x + self.pe[:, :seq_len]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1dnsy9b-zdS"
      },
      "source": [
        "## Transformer Encoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uTB87O5mpFTX"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "  def __init__(self, d_model, num_heads, d_ff, dropout = 0.1):\n",
        "    super().__init__()\n",
        "    self.self_attention = nn.MultiheadAttention(d_model, num_heads, dropout = dropout, batch_first = True)\n",
        "    self.linear1 = nn.Linear(d_model, d_ff)\n",
        "    self.linear2 = nn.Linear(d_ff, d_model)\n",
        "    self.norm1 = nn.LayerNorm(d_model)\n",
        "    self.norm2 = nn.LayerNorm(d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, src_mask = None, src_key_padding_mask = None):\n",
        "    attention_output, _ = self.self_attention(x, x, x, attn_mask = src_mask, key_padding_mask = src_key_padding_mask)\n",
        "    x2 = self.dropout(attention_output) + x\n",
        "    x = self.norm1(x2)\n",
        "    ff = self.linear2(self.dropout(torch.relu(self.linear1(x))))\n",
        "    ff = self.dropout(ff)\n",
        "    x = self.norm2(x + ff)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEmN0iZq-5pS"
      },
      "source": [
        "## Transformer Encoder embedder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zPmvNsy0934T"
      },
      "outputs": [],
      "source": [
        "class SentenceEmbeddingModel(nn.Module):\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               d_model = 512,\n",
        "               nhead = 8,\n",
        "               num_layers = 6,\n",
        "               dim_ff = 2048,\n",
        "               max_seq_len = 512,\n",
        "               dropout = 0.1\n",
        "               ):\n",
        "\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.token_embedding = nn.Embedding(vocab_size, d_model, padding_idx = 0)\n",
        "    self.positional_encoding = PositionalEncoding(d_model, max_len = max_seq_len)\n",
        "    self.encoder_layers = nn.ModuleList(\n",
        "        [TransformerEncoderBlock(d_model, nhead, dim_ff, dropout) for _ in range(num_layers)]\n",
        "    )\n",
        "\n",
        "  def mean_pooling(self, token_embeddings, attention_mask):\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min = 1e-9)\n",
        "        return sum_embeddings / sum_mask\n",
        "\n",
        "  def forward(self, src, attention_mask):\n",
        "    x = self.token_embedding(src)\n",
        "    x = x * math.sqrt(self.d_model)\n",
        "    x = self.positional_encoding(x)\n",
        "\n",
        "    key_padding_mask = (attention_mask == 0)\n",
        "\n",
        "    for layer in self.encoder_layers:\n",
        "      x = layer(x, src_key_padding_mask = key_padding_mask)\n",
        "    sentence_vector = self.mean_pooling(x, attention_mask)\n",
        "    return sentence_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzE5f5LK93cW"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WPN1jpSl91sf"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YzrAkcKqc84t"
      },
      "outputs": [],
      "source": [
        "def get_training_corpus(dataset):\n",
        "    batch_size = 1000\n",
        "    for i in range(0, len(dataset), batch_size):\n",
        "        batch = dataset[i : i + batch_size]\n",
        "        yield batch['query'] + batch['pos'] + batch['neg'] # combine the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IR5qR5XD97ui"
      },
      "outputs": [],
      "source": [
        "def train_custom_bpe_tokenizer(dataset, vocab_size = 30000):\n",
        "    tokenizer = Tokenizer(BPE(unk_token = \"[UNK]\")) # handle unknown characters\n",
        "    tokenizer.pre_tokenizer = Whitespace() # split the word by space\n",
        "\n",
        "    trainer = BpeTrainer(\n",
        "        vocab_size = vocab_size,\n",
        "        special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "    )\n",
        "\n",
        "    print(\"training BPE tokenizer...\")\n",
        "    tokenizer.train_from_iterator(get_training_corpus(dataset), trainer)\n",
        "\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhczfqvLdt5n"
      },
      "source": [
        "## Data integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iMdz2WD7elzO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YlN6nd_VUjB7"
      },
      "outputs": [],
      "source": [
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, tokenizer, max_len = 128):\n",
        "        self.dataset = hf_dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.tokenizer.enable_padding(pad_id = 0, pad_token = \"[PAD]\", length = max_len)\n",
        "        self.tokenizer.enable_truncation(max_length = max_len)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def encode_text(self, text):\n",
        "        enc = self.tokenizer.encode(text)\n",
        "        return torch.tensor(enc.ids, dtype = torch.long), torch.tensor(enc.attention_mask, dtype = torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataset[idx]\n",
        "\n",
        "        q_ids, q_mask = self.encode_text(row['query'])\n",
        "        p_ids, p_mask = self.encode_text(row['pos'])\n",
        "        n_ids, n_mask = self.encode_text(row['neg'])\n",
        "\n",
        "        return {\n",
        "            'q_ids': q_ids, 'q_mask': q_mask,\n",
        "            'p_ids': p_ids, 'p_mask': p_mask,\n",
        "            'n_ids': n_ids, 'n_mask': n_mask\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2x8jGFZn900"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "05b720f0b4cb437692bd1037d49d64ac",
            "c1bffe46513f475799f1ba7bcaf9eda2",
            "7b1ee7f53fe34a6f90a393e07b26f4db",
            "edaa01161ac443e88336597703749ea0",
            "8eacf44157904aadb53e23de1911f20d",
            "95870392877641499557ed6ed6b15b38",
            "07b08486debb4224a58fd4bc2d2d8777",
            "96eca56e290245c39c840ccc854295fe",
            "2652bac33bac494c8671488af2dcb7dd",
            "b6ee53b11c81485ca9216be7b1ebd141",
            "d8618e2aa66f4487b135326dbf77b0bd",
            "22cd7da3525446d5a9ccef223166e753",
            "e33c20ee3ee346448fb876508eba8fa8",
            "e51fa89532b146bda7861612c1feaee2",
            "32e8011a72e64cae85f5a80b0c594798",
            "c0303b5baa334815ad0a59bff5e4544e",
            "931fc409105c44b29cb900121279f204",
            "74b6543f5a8442208e2ee69ba0d34260",
            "2d137ccf33044bd6b97e1cb8765dfca2",
            "86755138798c430f98d49d5abe71d065",
            "67fb286a59f843be8c839315761d9e49",
            "ca8061a431244951af3d9e52455ed145",
            "8eb4ce9559a44aecab8c0b0ac31d8511",
            "d81272e4daf748ccaad0b73f642aad33",
            "9eb8d69001a34a4ea74e13d983b6e04e",
            "10ec6aa6471345e5bb86ac7a3e8a0e40",
            "734f461af3cc4d95b3dd491111cd3ea9",
            "cee3811f7d4e4282afc68a5f59a14b1b",
            "39fa7924f63d464189f02ac7b2793bc1",
            "836704d504f74434bd003b40166b6c10",
            "f9584619bb5c42ebb0b77b067a89fb5a",
            "b1a5c052bd1343f7a2854c18367adeb5",
            "10b2d9596d264790a32c08e748dc2919"
          ]
        },
        "id": "sTDM0IPbBxLJ",
        "outputId": "401ad296-b6ec-4734-d10f-d1b93f066d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounting google drive...\n",
            "Mounted at /content/drive\n",
            "Created directory in Drive: /content/drive/MyDrive/MedEmbed_Checkpoints\n",
            "Loading medical dataset from huggingface...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05b720f0b4cb437692bd1037d49d64ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22cd7da3525446d5a9ccef223166e753",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/59.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8eb4ce9559a44aecab8c0b0ac31d8511",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/232684 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded. Rows:  232684\n",
            "Columns:  ['query', 'pos', 'neg', 'query_id', 'pos_id', 'neg_id']\n",
            "Training tokenizer...\n",
            "training BPE tokenizer...\n",
            "Tokenizer saved to Drive: /content/drive/MyDrive/MedEmbed_Checkpoints/tokenizer.json\n",
            "\n",
            "Starting Training...\n",
            "Epoch 1, Batch 100/7272, Loss: 0.7643\n",
            "Epoch 1, Batch 200/7272, Loss: 0.6434\n",
            "Epoch 1, Batch 300/7272, Loss: 0.4567\n",
            "Epoch 1, Batch 400/7272, Loss: 0.5051\n",
            "Epoch 1, Batch 500/7272, Loss: 0.7626\n",
            "Epoch 1, Batch 600/7272, Loss: 0.6204\n",
            "Epoch 1, Batch 700/7272, Loss: 0.5324\n",
            "Epoch 1, Batch 800/7272, Loss: 0.5192\n",
            "Epoch 1, Batch 900/7272, Loss: 0.5735\n",
            "Epoch 1, Batch 1000/7272, Loss: 0.5651\n",
            "Epoch 1, Batch 1100/7272, Loss: 0.5170\n",
            "Epoch 1, Batch 1200/7272, Loss: 0.5679\n",
            "Epoch 1, Batch 1300/7272, Loss: 0.4556\n",
            "Epoch 1, Batch 1400/7272, Loss: 0.6683\n",
            "Epoch 1, Batch 1500/7272, Loss: 0.3793\n",
            "Epoch 1, Batch 1600/7272, Loss: 0.3390\n",
            "Epoch 1, Batch 1700/7272, Loss: 0.3630\n",
            "Epoch 1, Batch 1800/7272, Loss: 0.3780\n",
            "Epoch 1, Batch 1900/7272, Loss: 0.4421\n",
            "Epoch 1, Batch 2000/7272, Loss: 0.4733\n",
            "Epoch 1, Batch 2100/7272, Loss: 0.5697\n",
            "Epoch 1, Batch 2200/7272, Loss: 0.5848\n",
            "Epoch 1, Batch 2300/7272, Loss: 0.3717\n",
            "Epoch 1, Batch 2400/7272, Loss: 0.3558\n",
            "Epoch 1, Batch 2500/7272, Loss: 0.3112\n",
            "Epoch 1, Batch 2600/7272, Loss: 0.2931\n",
            "Epoch 1, Batch 2700/7272, Loss: 0.5126\n",
            "Epoch 1, Batch 2800/7272, Loss: 0.2927\n",
            "Epoch 1, Batch 2900/7272, Loss: 0.4089\n",
            "Epoch 1, Batch 3000/7272, Loss: 0.3273\n",
            "Epoch 1, Batch 3100/7272, Loss: 0.6835\n",
            "Epoch 1, Batch 3200/7272, Loss: 0.3927\n",
            "Epoch 1, Batch 3300/7272, Loss: 0.3359\n",
            "Epoch 1, Batch 3400/7272, Loss: 0.3881\n",
            "Epoch 1, Batch 3500/7272, Loss: 0.5120\n",
            "Epoch 1, Batch 3600/7272, Loss: 0.2495\n",
            "Epoch 1, Batch 3700/7272, Loss: 0.4283\n",
            "Epoch 1, Batch 3800/7272, Loss: 0.3770\n",
            "Epoch 1, Batch 3900/7272, Loss: 0.4803\n",
            "Epoch 1, Batch 4000/7272, Loss: 0.3204\n",
            "Epoch 1, Batch 4100/7272, Loss: 0.3069\n",
            "Epoch 1, Batch 4200/7272, Loss: 0.2214\n",
            "Epoch 1, Batch 4300/7272, Loss: 0.3583\n",
            "Epoch 1, Batch 4400/7272, Loss: 0.3077\n",
            "Epoch 1, Batch 4500/7272, Loss: 0.3533\n",
            "Epoch 1, Batch 4600/7272, Loss: 0.1892\n",
            "Epoch 1, Batch 4700/7272, Loss: 0.3067\n",
            "Epoch 1, Batch 4800/7272, Loss: 0.2523\n",
            "Epoch 1, Batch 4900/7272, Loss: 0.2709\n",
            "Epoch 1, Batch 5000/7272, Loss: 0.3194\n",
            "Epoch 1, Batch 5100/7272, Loss: 0.3427\n",
            "Epoch 1, Batch 5200/7272, Loss: 0.3370\n",
            "Epoch 1, Batch 5300/7272, Loss: 0.4898\n",
            "Epoch 1, Batch 5400/7272, Loss: 0.1560\n",
            "Epoch 1, Batch 5500/7272, Loss: 0.3371\n",
            "Epoch 1, Batch 5600/7272, Loss: 0.4245\n",
            "Epoch 1, Batch 5700/7272, Loss: 0.1825\n",
            "Epoch 1, Batch 5800/7272, Loss: 0.2238\n",
            "Epoch 1, Batch 5900/7272, Loss: 0.1508\n",
            "Epoch 1, Batch 6000/7272, Loss: 0.2703\n",
            "Epoch 1, Batch 6100/7272, Loss: 0.2721\n",
            "Epoch 1, Batch 6200/7272, Loss: 0.1882\n",
            "Epoch 1, Batch 6300/7272, Loss: 0.1926\n",
            "Epoch 1, Batch 6400/7272, Loss: 0.2766\n",
            "Epoch 1, Batch 6500/7272, Loss: 0.2386\n",
            "Epoch 1, Batch 6600/7272, Loss: 0.1707\n",
            "Epoch 1, Batch 6700/7272, Loss: 0.3214\n",
            "Epoch 1, Batch 6800/7272, Loss: 0.2331\n",
            "Epoch 1, Batch 6900/7272, Loss: 0.1143\n",
            "Epoch 1, Batch 7000/7272, Loss: 0.2527\n",
            "Epoch 1, Batch 7100/7272, Loss: 0.3346\n",
            "Epoch 1, Batch 7200/7272, Loss: 0.2361\n",
            "Epoch 1, Average Loss: 0.3996\n",
            "Saved checkpoint: /content/drive/MyDrive/MedEmbed_Checkpoints/model_epoch_1.pt\n",
            "Epoch 2, Batch 100/7272, Loss: 0.2870\n",
            "Epoch 2, Batch 200/7272, Loss: 0.0931\n",
            "Epoch 2, Batch 300/7272, Loss: 0.1481\n",
            "Epoch 2, Batch 400/7272, Loss: 0.1768\n",
            "Epoch 2, Batch 500/7272, Loss: 0.1682\n",
            "Epoch 2, Batch 600/7272, Loss: 0.1345\n",
            "Epoch 2, Batch 700/7272, Loss: 0.2932\n",
            "Epoch 2, Batch 800/7272, Loss: 0.1731\n",
            "Epoch 2, Batch 900/7272, Loss: 0.0897\n",
            "Epoch 2, Batch 1000/7272, Loss: 0.2710\n",
            "Epoch 2, Batch 1100/7272, Loss: 0.2286\n",
            "Epoch 2, Batch 1200/7272, Loss: 0.0748\n",
            "Epoch 2, Batch 1300/7272, Loss: 0.2312\n",
            "Epoch 2, Batch 1400/7272, Loss: 0.1375\n",
            "Epoch 2, Batch 1500/7272, Loss: 0.1721\n",
            "Epoch 2, Batch 1600/7272, Loss: 0.1954\n",
            "Epoch 2, Batch 1700/7272, Loss: 0.2020\n",
            "Epoch 2, Batch 1800/7272, Loss: 0.1319\n",
            "Epoch 2, Batch 1900/7272, Loss: 0.1642\n",
            "Epoch 2, Batch 2000/7272, Loss: 0.2059\n",
            "Epoch 2, Batch 2100/7272, Loss: 0.3658\n",
            "Epoch 2, Batch 2200/7272, Loss: 0.1858\n",
            "Epoch 2, Batch 2300/7272, Loss: 0.2058\n",
            "Epoch 2, Batch 2400/7272, Loss: 0.1169\n",
            "Epoch 2, Batch 2500/7272, Loss: 0.1935\n",
            "Epoch 2, Batch 2600/7272, Loss: 0.3134\n",
            "Epoch 2, Batch 2700/7272, Loss: 0.0722\n",
            "Epoch 2, Batch 2800/7272, Loss: 0.1956\n",
            "Epoch 2, Batch 2900/7272, Loss: 0.2994\n",
            "Epoch 2, Batch 3000/7272, Loss: 0.1908\n",
            "Epoch 2, Batch 3100/7272, Loss: 0.3208\n",
            "Epoch 2, Batch 3200/7272, Loss: 0.3035\n",
            "Epoch 2, Batch 3300/7272, Loss: 0.1951\n",
            "Epoch 2, Batch 3400/7272, Loss: 0.1726\n",
            "Epoch 2, Batch 3500/7272, Loss: 0.2755\n",
            "Epoch 2, Batch 3600/7272, Loss: 0.2677\n",
            "Epoch 2, Batch 3700/7272, Loss: 0.1018\n",
            "Epoch 2, Batch 3800/7272, Loss: 0.1025\n",
            "Epoch 2, Batch 3900/7272, Loss: 0.2025\n",
            "Epoch 2, Batch 4000/7272, Loss: 0.1272\n",
            "Epoch 2, Batch 4100/7272, Loss: 0.2769\n",
            "Epoch 2, Batch 4200/7272, Loss: 0.2584\n",
            "Epoch 2, Batch 4300/7272, Loss: 0.2768\n",
            "Epoch 2, Batch 4400/7272, Loss: 0.3701\n",
            "Epoch 2, Batch 4500/7272, Loss: 0.1861\n",
            "Epoch 2, Batch 4600/7272, Loss: 0.0655\n",
            "Epoch 2, Batch 4700/7272, Loss: 0.2468\n",
            "Epoch 2, Batch 4800/7272, Loss: 0.1077\n",
            "Epoch 2, Batch 4900/7272, Loss: 0.1687\n",
            "Epoch 2, Batch 5000/7272, Loss: 0.2642\n",
            "Epoch 2, Batch 5100/7272, Loss: 0.1962\n",
            "Epoch 2, Batch 5200/7272, Loss: 0.2288\n",
            "Epoch 2, Batch 5300/7272, Loss: 0.1371\n",
            "Epoch 2, Batch 5400/7272, Loss: 0.1036\n",
            "Epoch 2, Batch 5500/7272, Loss: 0.0854\n",
            "Epoch 2, Batch 5600/7272, Loss: 0.2424\n",
            "Epoch 2, Batch 5700/7272, Loss: 0.1181\n",
            "Epoch 2, Batch 5800/7272, Loss: 0.1793\n",
            "Epoch 2, Batch 5900/7272, Loss: 0.2029\n",
            "Epoch 2, Batch 6000/7272, Loss: 0.2238\n",
            "Epoch 2, Batch 6100/7272, Loss: 0.1357\n",
            "Epoch 2, Batch 6200/7272, Loss: 0.1329\n",
            "Epoch 2, Batch 6300/7272, Loss: 0.0816\n",
            "Epoch 2, Batch 6400/7272, Loss: 0.1422\n",
            "Epoch 2, Batch 6500/7272, Loss: 0.2184\n",
            "Epoch 2, Batch 6600/7272, Loss: 0.0660\n",
            "Epoch 2, Batch 6700/7272, Loss: 0.0889\n",
            "Epoch 2, Batch 6800/7272, Loss: 0.3563\n",
            "Epoch 2, Batch 6900/7272, Loss: 0.1398\n",
            "Epoch 2, Batch 7000/7272, Loss: 0.0714\n",
            "Epoch 2, Batch 7100/7272, Loss: 0.0675\n",
            "Epoch 2, Batch 7200/7272, Loss: 0.1949\n",
            "Epoch 2, Average Loss: 0.1926\n",
            "Saved checkpoint: /content/drive/MyDrive/MedEmbed_Checkpoints/model_epoch_2.pt\n",
            "Epoch 3, Batch 100/7272, Loss: 0.2617\n",
            "Epoch 3, Batch 200/7272, Loss: 0.0754\n",
            "Epoch 3, Batch 300/7272, Loss: 0.3140\n",
            "Epoch 3, Batch 400/7272, Loss: 0.1519\n",
            "Epoch 3, Batch 500/7272, Loss: 0.2120\n",
            "Epoch 3, Batch 600/7272, Loss: 0.2222\n",
            "Epoch 3, Batch 700/7272, Loss: 0.0983\n",
            "Epoch 3, Batch 800/7272, Loss: 0.1167\n",
            "Epoch 3, Batch 900/7272, Loss: 0.0869\n",
            "Epoch 3, Batch 1000/7272, Loss: 0.1263\n",
            "Epoch 3, Batch 1100/7272, Loss: 0.3516\n",
            "Epoch 3, Batch 1200/7272, Loss: 0.1560\n",
            "Epoch 3, Batch 1300/7272, Loss: 0.0534\n",
            "Epoch 3, Batch 1400/7272, Loss: 0.0931\n",
            "Epoch 3, Batch 1500/7272, Loss: 0.0943\n",
            "Epoch 3, Batch 1600/7272, Loss: 0.1136\n",
            "Epoch 3, Batch 1700/7272, Loss: 0.1003\n",
            "Epoch 3, Batch 1800/7272, Loss: 0.1542\n",
            "Epoch 3, Batch 1900/7272, Loss: 0.0060\n",
            "Epoch 3, Batch 2000/7272, Loss: 0.1221\n",
            "Epoch 3, Batch 2100/7272, Loss: 0.1975\n",
            "Epoch 3, Batch 2200/7272, Loss: 0.1434\n",
            "Epoch 3, Batch 2300/7272, Loss: 0.1238\n",
            "Epoch 3, Batch 2400/7272, Loss: 0.0173\n",
            "Epoch 3, Batch 2500/7272, Loss: 0.1178\n",
            "Epoch 3, Batch 2600/7272, Loss: 0.2196\n",
            "Epoch 3, Batch 2700/7272, Loss: 0.3358\n",
            "Epoch 3, Batch 2800/7272, Loss: 0.0900\n",
            "Epoch 3, Batch 2900/7272, Loss: 0.0586\n",
            "Epoch 3, Batch 3000/7272, Loss: 0.1356\n",
            "Epoch 3, Batch 3100/7272, Loss: 0.1152\n",
            "Epoch 3, Batch 3200/7272, Loss: 0.1722\n",
            "Epoch 3, Batch 3300/7272, Loss: 0.1450\n",
            "Epoch 3, Batch 3400/7272, Loss: 0.0273\n",
            "Epoch 3, Batch 3500/7272, Loss: 0.1735\n",
            "Epoch 3, Batch 3600/7272, Loss: 0.1418\n",
            "Epoch 3, Batch 3700/7272, Loss: 0.1756\n",
            "Epoch 3, Batch 3800/7272, Loss: 0.0843\n",
            "Epoch 3, Batch 3900/7272, Loss: 0.1382\n",
            "Epoch 3, Batch 4000/7272, Loss: 0.0169\n",
            "Epoch 3, Batch 4100/7272, Loss: 0.0869\n",
            "Epoch 3, Batch 4200/7272, Loss: 0.0638\n",
            "Epoch 3, Batch 4300/7272, Loss: 0.1056\n",
            "Epoch 3, Batch 4400/7272, Loss: 0.1589\n",
            "Epoch 3, Batch 4500/7272, Loss: 0.1477\n",
            "Epoch 3, Batch 4600/7272, Loss: 0.1375\n",
            "Epoch 3, Batch 4700/7272, Loss: 0.1526\n",
            "Epoch 3, Batch 4800/7272, Loss: 0.2019\n",
            "Epoch 3, Batch 4900/7272, Loss: 0.1259\n",
            "Epoch 3, Batch 5000/7272, Loss: 0.1554\n",
            "Epoch 3, Batch 5100/7272, Loss: 0.2666\n",
            "Epoch 3, Batch 5200/7272, Loss: 0.1257\n",
            "Epoch 3, Batch 5300/7272, Loss: 0.0693\n",
            "Epoch 3, Batch 5400/7272, Loss: 0.0903\n",
            "Epoch 3, Batch 5500/7272, Loss: 0.1135\n",
            "Epoch 3, Batch 5600/7272, Loss: 0.0449\n",
            "Epoch 3, Batch 5700/7272, Loss: 0.1585\n",
            "Epoch 3, Batch 5800/7272, Loss: 0.1655\n",
            "Epoch 3, Batch 5900/7272, Loss: 0.0844\n",
            "Epoch 3, Batch 6000/7272, Loss: 0.1806\n",
            "Epoch 3, Batch 6100/7272, Loss: 0.1610\n",
            "Epoch 3, Batch 6200/7272, Loss: 0.0341\n",
            "Epoch 3, Batch 6300/7272, Loss: 0.0812\n",
            "Epoch 3, Batch 6400/7272, Loss: 0.1241\n",
            "Epoch 3, Batch 6500/7272, Loss: 0.1136\n",
            "Epoch 3, Batch 6600/7272, Loss: 0.1176\n",
            "Epoch 3, Batch 6700/7272, Loss: 0.1223\n",
            "Epoch 3, Batch 6800/7272, Loss: 0.0807\n",
            "Epoch 3, Batch 6900/7272, Loss: 0.0748\n",
            "Epoch 3, Batch 7000/7272, Loss: 0.0765\n",
            "Epoch 3, Batch 7100/7272, Loss: 0.1294\n",
            "Epoch 3, Batch 7200/7272, Loss: 0.1366\n",
            "Epoch 3, Average Loss: 0.1222\n",
            "Saved checkpoint: /content/drive/MyDrive/MedEmbed_Checkpoints/model_epoch_3.pt\n",
            "Epoch 4, Batch 100/7272, Loss: 0.0522\n",
            "Epoch 4, Batch 200/7272, Loss: 0.0059\n",
            "Epoch 4, Batch 300/7272, Loss: 0.1092\n",
            "Epoch 4, Batch 400/7272, Loss: 0.0061\n",
            "Epoch 4, Batch 500/7272, Loss: 0.0363\n",
            "Epoch 4, Batch 600/7272, Loss: 0.2225\n",
            "Epoch 4, Batch 700/7272, Loss: 0.0000\n",
            "Epoch 4, Batch 800/7272, Loss: 0.0551\n",
            "Epoch 4, Batch 900/7272, Loss: 0.1484\n",
            "Epoch 4, Batch 1000/7272, Loss: 0.0000\n",
            "Epoch 4, Batch 1100/7272, Loss: 0.0524\n",
            "Epoch 4, Batch 1200/7272, Loss: 0.1182\n",
            "Epoch 4, Batch 1300/7272, Loss: 0.0442\n",
            "Epoch 4, Batch 1400/7272, Loss: 0.0756\n",
            "Epoch 4, Batch 1500/7272, Loss: 0.0926\n",
            "Epoch 4, Batch 1600/7272, Loss: 0.0606\n",
            "Epoch 4, Batch 1700/7272, Loss: 0.0958\n",
            "Epoch 4, Batch 1800/7272, Loss: 0.0461\n",
            "Epoch 4, Batch 1900/7272, Loss: 0.1197\n",
            "Epoch 4, Batch 2000/7272, Loss: 0.0717\n",
            "Epoch 4, Batch 2100/7272, Loss: 0.0207\n",
            "Epoch 4, Batch 2200/7272, Loss: 0.1595\n",
            "Epoch 4, Batch 2300/7272, Loss: 0.0000\n",
            "Epoch 4, Batch 2400/7272, Loss: 0.0025\n",
            "Epoch 4, Batch 2500/7272, Loss: 0.1845\n",
            "Epoch 4, Batch 2600/7272, Loss: 0.1497\n",
            "Epoch 4, Batch 2700/7272, Loss: 0.0241\n",
            "Epoch 4, Batch 2800/7272, Loss: 0.0180\n",
            "Epoch 4, Batch 2900/7272, Loss: 0.0068\n",
            "Epoch 4, Batch 3000/7272, Loss: 0.1397\n",
            "Epoch 4, Batch 3100/7272, Loss: 0.0307\n",
            "Epoch 4, Batch 3200/7272, Loss: 0.0801\n",
            "Epoch 4, Batch 3300/7272, Loss: 0.1892\n",
            "Epoch 4, Batch 3400/7272, Loss: 0.0696\n",
            "Epoch 4, Batch 3500/7272, Loss: 0.0772\n",
            "Epoch 4, Batch 3600/7272, Loss: 0.0697\n",
            "Epoch 4, Batch 3700/7272, Loss: 0.1837\n",
            "Epoch 4, Batch 3800/7272, Loss: 0.1917\n",
            "Epoch 4, Batch 3900/7272, Loss: 0.1253\n",
            "Epoch 4, Batch 4000/7272, Loss: 0.0543\n",
            "Epoch 4, Batch 4100/7272, Loss: 0.0960\n",
            "Epoch 4, Batch 4200/7272, Loss: 0.1268\n",
            "Epoch 4, Batch 4300/7272, Loss: 0.0571\n",
            "Epoch 4, Batch 4400/7272, Loss: 0.1707\n",
            "Epoch 4, Batch 4500/7272, Loss: 0.0544\n",
            "Epoch 4, Batch 4600/7272, Loss: 0.1215\n",
            "Epoch 4, Batch 4700/7272, Loss: 0.1128\n",
            "Epoch 4, Batch 4800/7272, Loss: 0.0276\n",
            "Epoch 4, Batch 4900/7272, Loss: 0.0276\n",
            "Epoch 4, Batch 5000/7272, Loss: 0.0154\n",
            "Epoch 4, Batch 5100/7272, Loss: 0.0022\n",
            "Epoch 4, Batch 5200/7272, Loss: 0.0416\n",
            "Epoch 4, Batch 5300/7272, Loss: 0.1810\n",
            "Epoch 4, Batch 5400/7272, Loss: 0.0194\n",
            "Epoch 4, Batch 5500/7272, Loss: 0.1003\n",
            "Epoch 4, Batch 5600/7272, Loss: 0.0487\n",
            "Epoch 4, Batch 5700/7272, Loss: 0.0421\n",
            "Epoch 4, Batch 5800/7272, Loss: 0.0560\n",
            "Epoch 4, Batch 5900/7272, Loss: 0.0000\n",
            "Epoch 4, Batch 6000/7272, Loss: 0.1730\n",
            "Epoch 4, Batch 6100/7272, Loss: 0.0068\n",
            "Epoch 4, Batch 6200/7272, Loss: 0.0635\n",
            "Epoch 4, Batch 6300/7272, Loss: 0.0811\n",
            "Epoch 4, Batch 6400/7272, Loss: 0.0574\n",
            "Epoch 4, Batch 6500/7272, Loss: 0.0976\n",
            "Epoch 4, Batch 6600/7272, Loss: 0.1105\n",
            "Epoch 4, Batch 6700/7272, Loss: 0.1214\n",
            "Epoch 4, Batch 6800/7272, Loss: 0.0191\n",
            "Epoch 4, Batch 6900/7272, Loss: 0.0729\n",
            "Epoch 4, Batch 7000/7272, Loss: 0.0194\n",
            "Epoch 4, Batch 7100/7272, Loss: 0.1116\n",
            "Epoch 4, Batch 7200/7272, Loss: 0.1779\n",
            "Epoch 4, Average Loss: 0.0868\n",
            "Saved checkpoint: /content/drive/MyDrive/MedEmbed_Checkpoints/model_epoch_4.pt\n",
            "Epoch 5, Batch 100/7272, Loss: 0.0891\n",
            "Epoch 5, Batch 200/7272, Loss: 0.0437\n",
            "Epoch 5, Batch 300/7272, Loss: 0.0216\n",
            "Epoch 5, Batch 400/7272, Loss: 0.0693\n",
            "Epoch 5, Batch 500/7272, Loss: 0.0000\n",
            "Epoch 5, Batch 600/7272, Loss: 0.0824\n",
            "Epoch 5, Batch 700/7272, Loss: 0.0032\n",
            "Epoch 5, Batch 800/7272, Loss: 0.0256\n",
            "Epoch 5, Batch 900/7272, Loss: 0.0139\n",
            "Epoch 5, Batch 1000/7272, Loss: 0.0809\n",
            "Epoch 5, Batch 1100/7272, Loss: 0.0069\n",
            "Epoch 5, Batch 1200/7272, Loss: 0.0799\n",
            "Epoch 5, Batch 1300/7272, Loss: 0.0311\n",
            "Epoch 5, Batch 1400/7272, Loss: 0.0830\n",
            "Epoch 5, Batch 1500/7272, Loss: 0.2001\n",
            "Epoch 5, Batch 1600/7272, Loss: 0.1306\n",
            "Epoch 5, Batch 1700/7272, Loss: 0.0092\n",
            "Epoch 5, Batch 1800/7272, Loss: 0.0432\n",
            "Epoch 5, Batch 1900/7272, Loss: 0.1071\n",
            "Epoch 5, Batch 2000/7272, Loss: 0.1022\n",
            "Epoch 5, Batch 2100/7272, Loss: 0.1023\n",
            "Epoch 5, Batch 2200/7272, Loss: 0.0802\n",
            "Epoch 5, Batch 2300/7272, Loss: 0.0551\n",
            "Epoch 5, Batch 2400/7272, Loss: 0.1154\n",
            "Epoch 5, Batch 2500/7272, Loss: 0.0499\n",
            "Epoch 5, Batch 2600/7272, Loss: 0.0250\n",
            "Epoch 5, Batch 2700/7272, Loss: 0.1741\n",
            "Epoch 5, Batch 2800/7272, Loss: 0.0734\n",
            "Epoch 5, Batch 2900/7272, Loss: 0.1249\n",
            "Epoch 5, Batch 3000/7272, Loss: 0.0165\n",
            "Epoch 5, Batch 3100/7272, Loss: 0.0322\n",
            "Epoch 5, Batch 3200/7272, Loss: 0.0000\n",
            "Epoch 5, Batch 3300/7272, Loss: 0.1454\n",
            "Epoch 5, Batch 3400/7272, Loss: 0.0596\n",
            "Epoch 5, Batch 3500/7272, Loss: 0.0582\n",
            "Epoch 5, Batch 3600/7272, Loss: 0.0898\n",
            "Epoch 5, Batch 3700/7272, Loss: 0.0657\n",
            "Epoch 5, Batch 3800/7272, Loss: 0.0582\n",
            "Epoch 5, Batch 3900/7272, Loss: 0.2043\n",
            "Epoch 5, Batch 4000/7272, Loss: 0.0000\n",
            "Epoch 5, Batch 4100/7272, Loss: 0.0496\n",
            "Epoch 5, Batch 4200/7272, Loss: 0.2104\n",
            "Epoch 5, Batch 4300/7272, Loss: 0.1126\n",
            "Epoch 5, Batch 4400/7272, Loss: 0.0710\n",
            "Epoch 5, Batch 4500/7272, Loss: 0.0000\n",
            "Epoch 5, Batch 4600/7272, Loss: 0.0000\n",
            "Epoch 5, Batch 4700/7272, Loss: 0.0232\n",
            "Epoch 5, Batch 4800/7272, Loss: 0.0330\n",
            "Epoch 5, Batch 4900/7272, Loss: 0.0552\n",
            "Epoch 5, Batch 5000/7272, Loss: 0.1641\n",
            "Epoch 5, Batch 5100/7272, Loss: 0.0618\n",
            "Epoch 5, Batch 5200/7272, Loss: 0.1531\n",
            "Epoch 5, Batch 5300/7272, Loss: 0.0190\n",
            "Epoch 5, Batch 5400/7272, Loss: 0.0953\n",
            "Epoch 5, Batch 5500/7272, Loss: 0.1731\n",
            "Epoch 5, Batch 5600/7272, Loss: 0.0471\n",
            "Epoch 5, Batch 5700/7272, Loss: 0.1149\n",
            "Epoch 5, Batch 5800/7272, Loss: 0.0053\n",
            "Epoch 5, Batch 5900/7272, Loss: 0.0449\n",
            "Epoch 5, Batch 6000/7272, Loss: 0.0609\n",
            "Epoch 5, Batch 6100/7272, Loss: 0.0984\n",
            "Epoch 5, Batch 6200/7272, Loss: 0.0372\n",
            "Epoch 5, Batch 6300/7272, Loss: 0.0281\n",
            "Epoch 5, Batch 6400/7272, Loss: 0.0383\n",
            "Epoch 5, Batch 6500/7272, Loss: 0.0812\n",
            "Epoch 5, Batch 6600/7272, Loss: 0.0179\n",
            "Epoch 5, Batch 6700/7272, Loss: 0.0192\n",
            "Epoch 5, Batch 6800/7272, Loss: 0.0690\n",
            "Epoch 5, Batch 6900/7272, Loss: 0.0165\n",
            "Epoch 5, Batch 7000/7272, Loss: 0.0519\n",
            "Epoch 5, Batch 7100/7272, Loss: 0.0890\n",
            "Epoch 5, Batch 7200/7272, Loss: 0.0188\n",
            "Epoch 5, Average Loss: 0.0675\n",
            "Saved checkpoint: /content/drive/MyDrive/MedEmbed_Checkpoints/model_epoch_5.pt\n",
            "Epoch 6, Batch 100/7272, Loss: 0.0560\n",
            "Epoch 6, Batch 200/7272, Loss: 0.0476\n",
            "Epoch 6, Batch 300/7272, Loss: 0.0597\n",
            "Epoch 6, Batch 400/7272, Loss: 0.0242\n",
            "Epoch 6, Batch 500/7272, Loss: 0.0433\n",
            "Epoch 6, Batch 600/7272, Loss: 0.0125\n",
            "Epoch 6, Batch 700/7272, Loss: 0.0325\n",
            "Epoch 6, Batch 800/7272, Loss: 0.0061\n",
            "Epoch 6, Batch 900/7272, Loss: 0.0159\n",
            "Epoch 6, Batch 1000/7272, Loss: 0.0507\n",
            "Epoch 6, Batch 1100/7272, Loss: 0.0202\n",
            "Epoch 6, Batch 1200/7272, Loss: 0.0699\n",
            "Epoch 6, Batch 1300/7272, Loss: 0.0679\n",
            "Epoch 6, Batch 1400/7272, Loss: 0.0572\n",
            "Epoch 6, Batch 1500/7272, Loss: 0.0643\n",
            "Epoch 6, Batch 1600/7272, Loss: 0.0185\n",
            "Epoch 6, Batch 1700/7272, Loss: 0.0646\n",
            "Epoch 6, Batch 1800/7272, Loss: 0.0250\n",
            "Epoch 6, Batch 1900/7272, Loss: 0.1382\n",
            "Epoch 6, Batch 2000/7272, Loss: 0.0801\n",
            "Epoch 6, Batch 2100/7272, Loss: 0.0127\n",
            "Epoch 6, Batch 2200/7272, Loss: 0.1246\n",
            "Epoch 6, Batch 2300/7272, Loss: 0.0925\n",
            "Epoch 6, Batch 2400/7272, Loss: 0.0168\n",
            "Epoch 6, Batch 2500/7272, Loss: 0.1048\n",
            "Epoch 6, Batch 2600/7272, Loss: 0.0000\n",
            "Epoch 6, Batch 2700/7272, Loss: 0.0268\n",
            "Epoch 6, Batch 2800/7272, Loss: 0.0267\n",
            "Epoch 6, Batch 2900/7272, Loss: 0.0420\n",
            "Epoch 6, Batch 3000/7272, Loss: 0.0189\n",
            "Epoch 6, Batch 3100/7272, Loss: 0.0526\n",
            "Epoch 6, Batch 3200/7272, Loss: 0.0417\n",
            "Epoch 6, Batch 3300/7272, Loss: 0.0364\n",
            "Epoch 6, Batch 3400/7272, Loss: 0.0691\n",
            "Epoch 6, Batch 3500/7272, Loss: 0.0072\n",
            "Epoch 6, Batch 3600/7272, Loss: 0.0620\n",
            "Epoch 6, Batch 3700/7272, Loss: 0.0755\n",
            "Epoch 6, Batch 3800/7272, Loss: 0.0554\n",
            "Epoch 6, Batch 3900/7272, Loss: 0.0424\n",
            "Epoch 6, Batch 4000/7272, Loss: 0.1446\n",
            "Epoch 6, Batch 4100/7272, Loss: 0.0447\n",
            "Epoch 6, Batch 4200/7272, Loss: 0.0344\n",
            "Epoch 6, Batch 4300/7272, Loss: 0.0624\n",
            "Epoch 6, Batch 4400/7272, Loss: 0.0864\n",
            "Epoch 6, Batch 4500/7272, Loss: 0.1229\n",
            "Epoch 6, Batch 4600/7272, Loss: 0.0557\n",
            "Epoch 6, Batch 4700/7272, Loss: 0.0000\n",
            "Epoch 6, Batch 4800/7272, Loss: 0.0866\n",
            "Epoch 6, Batch 4900/7272, Loss: 0.0696\n",
            "Epoch 6, Batch 5000/7272, Loss: 0.1058\n",
            "Epoch 6, Batch 5100/7272, Loss: 0.0154\n",
            "Epoch 6, Batch 5200/7272, Loss: 0.0118\n",
            "Epoch 6, Batch 5300/7272, Loss: 0.0148\n",
            "Epoch 6, Batch 5400/7272, Loss: 0.0031\n",
            "Epoch 6, Batch 5500/7272, Loss: 0.0634\n",
            "Epoch 6, Batch 5600/7272, Loss: 0.0213\n",
            "Epoch 6, Batch 5700/7272, Loss: 0.0423\n",
            "Epoch 6, Batch 5800/7272, Loss: 0.2132\n",
            "Epoch 6, Batch 5900/7272, Loss: 0.0818\n",
            "Epoch 6, Batch 6000/7272, Loss: 0.1278\n",
            "Epoch 6, Batch 6100/7272, Loss: 0.0071\n",
            "Epoch 6, Batch 6200/7272, Loss: 0.0445\n",
            "Epoch 6, Batch 6300/7272, Loss: 0.0798\n",
            "Epoch 6, Batch 6400/7272, Loss: 0.0265\n",
            "Epoch 6, Batch 6500/7272, Loss: 0.0652\n",
            "Epoch 6, Batch 6600/7272, Loss: 0.0845\n",
            "Epoch 6, Batch 6700/7272, Loss: 0.0525\n",
            "Epoch 6, Batch 6800/7272, Loss: 0.0000\n",
            "Epoch 6, Batch 6900/7272, Loss: 0.0277\n",
            "Epoch 6, Batch 7000/7272, Loss: 0.0093\n",
            "Epoch 6, Batch 7100/7272, Loss: 0.0000\n",
            "Epoch 6, Batch 7200/7272, Loss: 0.0542\n",
            "Epoch 6, Average Loss: 0.0545\n",
            "Saved checkpoint: /content/drive/MyDrive/MedEmbed_Checkpoints/model_epoch_6.pt\n",
            "Epoch 7, Batch 100/7272, Loss: 0.0089\n",
            "Epoch 7, Batch 200/7272, Loss: 0.0193\n",
            "Epoch 7, Batch 300/7272, Loss: 0.0243\n",
            "Epoch 7, Batch 400/7272, Loss: 0.0693\n",
            "Epoch 7, Batch 500/7272, Loss: 0.0251\n",
            "Epoch 7, Batch 600/7272, Loss: 0.0000\n",
            "Epoch 7, Batch 700/7272, Loss: 0.0000\n",
            "Epoch 7, Batch 800/7272, Loss: 0.1187\n",
            "Epoch 7, Batch 900/7272, Loss: 0.0449\n",
            "Epoch 7, Batch 1000/7272, Loss: 0.0066\n",
            "Epoch 7, Batch 1100/7272, Loss: 0.0454\n",
            "Epoch 7, Batch 1200/7272, Loss: 0.0495\n",
            "Epoch 7, Batch 1300/7272, Loss: 0.0160\n",
            "Epoch 7, Batch 1400/7272, Loss: 0.0129\n",
            "Epoch 7, Batch 1500/7272, Loss: 0.0880\n",
            "Epoch 7, Batch 1600/7272, Loss: 0.0186\n",
            "Epoch 7, Batch 1700/7272, Loss: 0.0285\n",
            "Epoch 7, Batch 1800/7272, Loss: 0.0000\n",
            "Epoch 7, Batch 1900/7272, Loss: 0.0032\n",
            "Epoch 7, Batch 2000/7272, Loss: 0.0746\n",
            "Epoch 7, Batch 2100/7272, Loss: 0.0440\n",
            "Epoch 7, Batch 2200/7272, Loss: 0.0390\n",
            "Epoch 7, Batch 2300/7272, Loss: 0.0322\n",
            "Epoch 7, Batch 2400/7272, Loss: 0.0902\n",
            "Epoch 7, Batch 2500/7272, Loss: 0.0362\n",
            "Epoch 7, Batch 2600/7272, Loss: 0.0712\n",
            "Epoch 7, Batch 2700/7272, Loss: 0.0857\n",
            "Epoch 7, Batch 2800/7272, Loss: 0.0009\n",
            "Epoch 7, Batch 2900/7272, Loss: 0.0592\n",
            "Epoch 7, Batch 3000/7272, Loss: 0.0069\n",
            "Epoch 7, Batch 3100/7272, Loss: 0.0365\n",
            "Epoch 7, Batch 3200/7272, Loss: 0.0025\n",
            "Epoch 7, Batch 3300/7272, Loss: 0.0038\n",
            "Epoch 7, Batch 3400/7272, Loss: 0.0247\n",
            "Epoch 7, Batch 3500/7272, Loss: 0.0146\n",
            "Epoch 7, Batch 3600/7272, Loss: 0.0194\n",
            "Epoch 7, Batch 3700/7272, Loss: 0.1170\n",
            "Epoch 7, Batch 3800/7272, Loss: 0.0663\n",
            "Epoch 7, Batch 3900/7272, Loss: 0.0402\n",
            "Epoch 7, Batch 4000/7272, Loss: 0.0364\n",
            "Epoch 7, Batch 4100/7272, Loss: 0.0366\n",
            "Epoch 7, Batch 4200/7272, Loss: 0.0176\n",
            "Epoch 7, Batch 4300/7272, Loss: 0.0394\n",
            "Epoch 7, Batch 4400/7272, Loss: 0.0419\n",
            "Epoch 7, Batch 4500/7272, Loss: 0.0552\n",
            "Epoch 7, Batch 4600/7272, Loss: 0.0000\n",
            "Epoch 7, Batch 4700/7272, Loss: 0.0654\n",
            "Epoch 7, Batch 4800/7272, Loss: 0.0830\n",
            "Epoch 7, Batch 4900/7272, Loss: 0.0575\n",
            "Epoch 7, Batch 5000/7272, Loss: 0.0000\n",
            "Epoch 7, Batch 5100/7272, Loss: 0.0206\n",
            "Epoch 7, Batch 5200/7272, Loss: 0.0248\n",
            "Epoch 7, Batch 5300/7272, Loss: 0.0974\n",
            "Epoch 7, Batch 5400/7272, Loss: 0.0606\n",
            "Epoch 7, Batch 5500/7272, Loss: 0.0839\n",
            "Epoch 7, Batch 5600/7272, Loss: 0.0328\n",
            "Epoch 7, Batch 5700/7272, Loss: 0.1090\n",
            "Epoch 7, Batch 5800/7272, Loss: 0.0958\n",
            "Epoch 7, Batch 5900/7272, Loss: 0.0877\n",
            "Epoch 7, Batch 6000/7272, Loss: 0.0023\n",
            "Epoch 7, Batch 6100/7272, Loss: 0.0547\n",
            "Epoch 7, Batch 6200/7272, Loss: 0.0000\n",
            "Epoch 7, Batch 6300/7272, Loss: 0.1305\n",
            "Epoch 7, Batch 6400/7272, Loss: 0.0409\n",
            "Epoch 7, Batch 6500/7272, Loss: 0.0000\n",
            "Epoch 7, Batch 6600/7272, Loss: 0.0050\n",
            "Epoch 7, Batch 6700/7272, Loss: 0.0440\n",
            "Epoch 7, Batch 6800/7272, Loss: 0.0427\n",
            "Epoch 7, Batch 6900/7272, Loss: 0.0383\n",
            "Epoch 7, Batch 7000/7272, Loss: 0.0000\n",
            "Epoch 7, Batch 7100/7272, Loss: 0.0265\n",
            "Epoch 7, Batch 7200/7272, Loss: 0.0340\n",
            "Epoch 7, Average Loss: 0.0461\n",
            "Saved checkpoint: /content/drive/MyDrive/MedEmbed_Checkpoints/model_epoch_7.pt\n",
            "Epoch 8, Batch 100/7272, Loss: 0.1111\n",
            "Epoch 8, Batch 200/7272, Loss: 0.1281\n",
            "Epoch 8, Batch 300/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 400/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 500/7272, Loss: 0.0802\n",
            "Epoch 8, Batch 600/7272, Loss: 0.0724\n",
            "Epoch 8, Batch 700/7272, Loss: 0.0273\n",
            "Epoch 8, Batch 800/7272, Loss: 0.0380\n",
            "Epoch 8, Batch 900/7272, Loss: 0.0028\n",
            "Epoch 8, Batch 1000/7272, Loss: 0.0518\n",
            "Epoch 8, Batch 1100/7272, Loss: 0.0260\n",
            "Epoch 8, Batch 1200/7272, Loss: 0.0005\n",
            "Epoch 8, Batch 1300/7272, Loss: 0.0151\n",
            "Epoch 8, Batch 1400/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 1500/7272, Loss: 0.1630\n",
            "Epoch 8, Batch 1600/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 1700/7272, Loss: 0.0149\n",
            "Epoch 8, Batch 1800/7272, Loss: 0.1042\n",
            "Epoch 8, Batch 1900/7272, Loss: 0.0833\n",
            "Epoch 8, Batch 2000/7272, Loss: 0.0449\n",
            "Epoch 8, Batch 2100/7272, Loss: 0.0295\n",
            "Epoch 8, Batch 2200/7272, Loss: 0.0405\n",
            "Epoch 8, Batch 2300/7272, Loss: 0.0246\n",
            "Epoch 8, Batch 2400/7272, Loss: 0.0174\n",
            "Epoch 8, Batch 2500/7272, Loss: 0.0958\n",
            "Epoch 8, Batch 2600/7272, Loss: 0.0182\n",
            "Epoch 8, Batch 2700/7272, Loss: 0.0249\n",
            "Epoch 8, Batch 2800/7272, Loss: 0.1663\n",
            "Epoch 8, Batch 2900/7272, Loss: 0.0910\n",
            "Epoch 8, Batch 3000/7272, Loss: 0.0014\n",
            "Epoch 8, Batch 3100/7272, Loss: 0.0166\n",
            "Epoch 8, Batch 3200/7272, Loss: 0.1423\n",
            "Epoch 8, Batch 3300/7272, Loss: 0.0294\n",
            "Epoch 8, Batch 3400/7272, Loss: 0.0142\n",
            "Epoch 8, Batch 3500/7272, Loss: 0.0366\n",
            "Epoch 8, Batch 3600/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 3700/7272, Loss: 0.0700\n",
            "Epoch 8, Batch 3800/7272, Loss: 0.0322\n",
            "Epoch 8, Batch 3900/7272, Loss: 0.0200\n",
            "Epoch 8, Batch 4000/7272, Loss: 0.0820\n",
            "Epoch 8, Batch 4100/7272, Loss: 0.0034\n",
            "Epoch 8, Batch 4200/7272, Loss: 0.0570\n",
            "Epoch 8, Batch 4300/7272, Loss: 0.0703\n",
            "Epoch 8, Batch 4400/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 4500/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 4600/7272, Loss: 0.0082\n",
            "Epoch 8, Batch 4700/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 4800/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 4900/7272, Loss: 0.0012\n",
            "Epoch 8, Batch 5000/7272, Loss: 0.0279\n",
            "Epoch 8, Batch 5100/7272, Loss: 0.0820\n",
            "Epoch 8, Batch 5200/7272, Loss: 0.1431\n",
            "Epoch 8, Batch 5300/7272, Loss: 0.0391\n",
            "Epoch 8, Batch 5400/7272, Loss: 0.0806\n",
            "Epoch 8, Batch 5500/7272, Loss: 0.0784\n",
            "Epoch 8, Batch 5600/7272, Loss: 0.0588\n",
            "Epoch 8, Batch 5700/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 5800/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 5900/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 6000/7272, Loss: 0.1103\n",
            "Epoch 8, Batch 6100/7272, Loss: 0.1015\n",
            "Epoch 8, Batch 6200/7272, Loss: 0.0510\n",
            "Epoch 8, Batch 6300/7272, Loss: 0.0015\n",
            "Epoch 8, Batch 6400/7272, Loss: 0.0000\n",
            "Epoch 8, Batch 6500/7272, Loss: 0.0705\n",
            "Epoch 8, Batch 6600/7272, Loss: 0.0450\n",
            "Epoch 8, Batch 6700/7272, Loss: 0.0518\n",
            "Epoch 8, Batch 6800/7272, Loss: 0.0298\n",
            "Epoch 8, Batch 6900/7272, Loss: 0.1073\n",
            "Epoch 8, Batch 7000/7272, Loss: 0.0381\n",
            "Epoch 8, Batch 7100/7272, Loss: 0.0723\n",
            "Epoch 8, Batch 7200/7272, Loss: 0.0000\n",
            "Epoch 8, Average Loss: 0.0387\n",
            "Saved checkpoint: /content/drive/MyDrive/MedEmbed_Checkpoints/model_epoch_8.pt\n",
            "Epoch 9, Batch 100/7272, Loss: 0.0988\n",
            "Epoch 9, Batch 200/7272, Loss: 0.0178\n",
            "Epoch 9, Batch 300/7272, Loss: 0.0737\n",
            "Epoch 9, Batch 400/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 500/7272, Loss: 0.0167\n",
            "Epoch 9, Batch 600/7272, Loss: 0.0536\n",
            "Epoch 9, Batch 700/7272, Loss: 0.0102\n",
            "Epoch 9, Batch 800/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 900/7272, Loss: 0.0610\n",
            "Epoch 9, Batch 1000/7272, Loss: 0.0259\n",
            "Epoch 9, Batch 1100/7272, Loss: 0.0523\n",
            "Epoch 9, Batch 1200/7272, Loss: 0.0264\n",
            "Epoch 9, Batch 1300/7272, Loss: 0.0008\n",
            "Epoch 9, Batch 1400/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 1500/7272, Loss: 0.0081\n",
            "Epoch 9, Batch 1600/7272, Loss: 0.0270\n",
            "Epoch 9, Batch 1700/7272, Loss: 0.0047\n",
            "Epoch 9, Batch 1800/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 1900/7272, Loss: 0.0600\n",
            "Epoch 9, Batch 2000/7272, Loss: 0.0811\n",
            "Epoch 9, Batch 2100/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 2200/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 2300/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 2400/7272, Loss: 0.0221\n",
            "Epoch 9, Batch 2500/7272, Loss: 0.0847\n",
            "Epoch 9, Batch 2600/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 2700/7272, Loss: 0.1188\n",
            "Epoch 9, Batch 2800/7272, Loss: 0.0994\n",
            "Epoch 9, Batch 2900/7272, Loss: 0.0695\n",
            "Epoch 9, Batch 3000/7272, Loss: 0.0054\n",
            "Epoch 9, Batch 3100/7272, Loss: 0.0084\n",
            "Epoch 9, Batch 3200/7272, Loss: 0.0255\n",
            "Epoch 9, Batch 3300/7272, Loss: 0.0794\n",
            "Epoch 9, Batch 3400/7272, Loss: 0.0223\n",
            "Epoch 9, Batch 3500/7272, Loss: 0.0217\n",
            "Epoch 9, Batch 3600/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 3700/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 3800/7272, Loss: 0.0442\n",
            "Epoch 9, Batch 3900/7272, Loss: 0.0158\n",
            "Epoch 9, Batch 4000/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 4100/7272, Loss: 0.0201\n",
            "Epoch 9, Batch 4200/7272, Loss: 0.0519\n",
            "Epoch 9, Batch 4300/7272, Loss: 0.0160\n",
            "Epoch 9, Batch 4400/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 4500/7272, Loss: 0.0080\n",
            "Epoch 9, Batch 4600/7272, Loss: 0.0196\n",
            "Epoch 9, Batch 4700/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 4800/7272, Loss: 0.0193\n",
            "Epoch 9, Batch 4900/7272, Loss: 0.0435\n",
            "Epoch 9, Batch 5000/7272, Loss: 0.0279\n",
            "Epoch 9, Batch 5100/7272, Loss: 0.1315\n",
            "Epoch 9, Batch 5200/7272, Loss: 0.0923\n",
            "Epoch 9, Batch 5300/7272, Loss: 0.0370\n",
            "Epoch 9, Batch 5400/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 5500/7272, Loss: 0.0466\n",
            "Epoch 9, Batch 5600/7272, Loss: 0.0466\n",
            "Epoch 9, Batch 5700/7272, Loss: 0.0085\n",
            "Epoch 9, Batch 5800/7272, Loss: 0.0012\n",
            "Epoch 9, Batch 5900/7272, Loss: 0.0695\n",
            "Epoch 9, Batch 6000/7272, Loss: 0.0203\n",
            "Epoch 9, Batch 6100/7272, Loss: 0.0010\n",
            "Epoch 9, Batch 6200/7272, Loss: 0.0550\n",
            "Epoch 9, Batch 6300/7272, Loss: 0.0041\n",
            "Epoch 9, Batch 6400/7272, Loss: 0.1481\n",
            "Epoch 9, Batch 6500/7272, Loss: 0.0531\n",
            "Epoch 9, Batch 6600/7272, Loss: 0.2002\n",
            "Epoch 9, Batch 6700/7272, Loss: 0.0509\n",
            "Epoch 9, Batch 6800/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 6900/7272, Loss: 0.0349\n",
            "Epoch 9, Batch 7000/7272, Loss: 0.0485\n",
            "Epoch 9, Batch 7100/7272, Loss: 0.0000\n",
            "Epoch 9, Batch 7200/7272, Loss: 0.0084\n",
            "Epoch 9, Average Loss: 0.0341\n",
            "Saved checkpoint: /content/drive/MyDrive/MedEmbed_Checkpoints/model_epoch_9.pt\n",
            "Epoch 10, Batch 100/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 200/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 300/7272, Loss: 0.0572\n",
            "Epoch 10, Batch 400/7272, Loss: 0.0576\n",
            "Epoch 10, Batch 500/7272, Loss: 0.0126\n",
            "Epoch 10, Batch 600/7272, Loss: 0.0335\n",
            "Epoch 10, Batch 700/7272, Loss: 0.0132\n",
            "Epoch 10, Batch 800/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 900/7272, Loss: 0.0613\n",
            "Epoch 10, Batch 1000/7272, Loss: 0.1445\n",
            "Epoch 10, Batch 1100/7272, Loss: 0.0242\n",
            "Epoch 10, Batch 1200/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 1300/7272, Loss: 0.0018\n",
            "Epoch 10, Batch 1400/7272, Loss: 0.0366\n",
            "Epoch 10, Batch 1500/7272, Loss: 0.0197\n",
            "Epoch 10, Batch 1600/7272, Loss: 0.0647\n",
            "Epoch 10, Batch 1700/7272, Loss: 0.0429\n",
            "Epoch 10, Batch 1800/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 1900/7272, Loss: 0.0270\n",
            "Epoch 10, Batch 2000/7272, Loss: 0.0143\n",
            "Epoch 10, Batch 2100/7272, Loss: 0.0702\n",
            "Epoch 10, Batch 2200/7272, Loss: 0.0081\n",
            "Epoch 10, Batch 2300/7272, Loss: 0.0232\n",
            "Epoch 10, Batch 2400/7272, Loss: 0.0108\n",
            "Epoch 10, Batch 2500/7272, Loss: 0.0264\n",
            "Epoch 10, Batch 2600/7272, Loss: 0.0228\n",
            "Epoch 10, Batch 2700/7272, Loss: 0.0196\n",
            "Epoch 10, Batch 2800/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 2900/7272, Loss: 0.0349\n",
            "Epoch 10, Batch 3000/7272, Loss: 0.0290\n",
            "Epoch 10, Batch 3100/7272, Loss: 0.0539\n",
            "Epoch 10, Batch 3200/7272, Loss: 0.0012\n",
            "Epoch 10, Batch 3300/7272, Loss: 0.0050\n",
            "Epoch 10, Batch 3400/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 3500/7272, Loss: 0.0422\n",
            "Epoch 10, Batch 3600/7272, Loss: 0.0297\n",
            "Epoch 10, Batch 3700/7272, Loss: 0.0936\n",
            "Epoch 10, Batch 3800/7272, Loss: 0.0127\n",
            "Epoch 10, Batch 3900/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 4000/7272, Loss: 0.1198\n",
            "Epoch 10, Batch 4100/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 4200/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 4300/7272, Loss: 0.0102\n",
            "Epoch 10, Batch 4400/7272, Loss: 0.0098\n",
            "Epoch 10, Batch 4500/7272, Loss: 0.0306\n",
            "Epoch 10, Batch 4600/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 4700/7272, Loss: 0.1328\n",
            "Epoch 10, Batch 4800/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 4900/7272, Loss: 0.1233\n",
            "Epoch 10, Batch 5000/7272, Loss: 0.0492\n",
            "Epoch 10, Batch 5100/7272, Loss: 0.0096\n",
            "Epoch 10, Batch 5200/7272, Loss: 0.0300\n",
            "Epoch 10, Batch 5300/7272, Loss: 0.0114\n",
            "Epoch 10, Batch 5400/7272, Loss: 0.0129\n",
            "Epoch 10, Batch 5500/7272, Loss: 0.0012\n",
            "Epoch 10, Batch 5600/7272, Loss: 0.0244\n",
            "Epoch 10, Batch 5700/7272, Loss: 0.0110\n",
            "Epoch 10, Batch 5800/7272, Loss: 0.0643\n",
            "Epoch 10, Batch 5900/7272, Loss: 0.0077\n",
            "Epoch 10, Batch 6000/7272, Loss: 0.0895\n",
            "Epoch 10, Batch 6100/7272, Loss: 0.0388\n",
            "Epoch 10, Batch 6200/7272, Loss: 0.0410\n",
            "Epoch 10, Batch 6300/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 6400/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 6500/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 6600/7272, Loss: 0.0000\n",
            "Epoch 10, Batch 6700/7272, Loss: 0.0219\n",
            "Epoch 10, Batch 6800/7272, Loss: 0.0335\n",
            "Epoch 10, Batch 6900/7272, Loss: 0.0663\n",
            "Epoch 10, Batch 7000/7272, Loss: 0.0495\n",
            "Epoch 10, Batch 7100/7272, Loss: 0.0377\n",
            "Epoch 10, Batch 7200/7272, Loss: 0.1491\n",
            "Epoch 10, Average Loss: 0.0305\n",
            "Saved checkpoint: /content/drive/MyDrive/MedEmbed_Checkpoints/model_epoch_10.pt\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    VOCAB_SIZE = 30000\n",
        "    MAX_SEQ_LEN = 128\n",
        "    BATCH_SIZE = 32\n",
        "    D_MODEL = 256\n",
        "    NHEAD = 4\n",
        "    NUM_LAYERS = 4\n",
        "    DIM_FF = 1024\n",
        "    DROPOUT = 0.1\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    NUM_EPOCHS = 10\n",
        "    SAVE_EVERY_EPOCH = 1\n",
        "\n",
        "    # saving tokenizer on drive\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "\n",
        "    print(\"Mounting google drive...\")\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    CHECKPOINT_DIR = \"/content/drive/MyDrive/MedEmbed_Checkpoints\"\n",
        "\n",
        "    if not os.path.exists(CHECKPOINT_DIR):\n",
        "        os.makedirs(CHECKPOINT_DIR)\n",
        "        print(f\"Created directory in Drive: {CHECKPOINT_DIR}\")\n",
        "    else:\n",
        "        print(f\"Using existing directory in Drive: {CHECKPOINT_DIR}\")\n",
        "\n",
        "    # load dataset\n",
        "    print(\"Loading medical dataset from huggingface...\")\n",
        "    full_dataset = load_dataset(\"abhinand/MedEmbed-training-triplets-v1\", split = \"train\")\n",
        "\n",
        "    # about dataset\n",
        "    print(\"Dataset loaded. Rows: \", len(full_dataset))\n",
        "    print(\"Columns: \", full_dataset.column_names)\n",
        "\n",
        "    tokenizer_path = os.path.join(CHECKPOINT_DIR, \"tokenizer.json\")\n",
        "\n",
        "    if os.path.exists(tokenizer_path):\n",
        "        print(f\"Loading tokenizer from Drive: {tokenizer_path}\")\n",
        "        tokenizer = Tokenizer.from_file(tokenizer_path)\n",
        "    else:\n",
        "        print(\"Training tokenizer...\")\n",
        "        tokenizer = train_custom_bpe_tokenizer(full_dataset, vocab_size = VOCAB_SIZE)\n",
        "        tokenizer.save(tokenizer_path)\n",
        "        print(f\"Tokenizer saved to Drive: {tokenizer_path}\")\n",
        "\n",
        "    # preparing model\n",
        "    train_dataset = TripletDataset(full_dataset, tokenizer, max_len = MAX_SEQ_LEN)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)\n",
        "\n",
        "    model = SentenceEmbeddingModel(\n",
        "        vocab_size = tokenizer.get_vocab_size(),\n",
        "        d_model = D_MODEL,\n",
        "        max_seq_len = MAX_SEQ_LEN,\n",
        "        nhead = NHEAD,\n",
        "        num_layers = NUM_LAYERS,\n",
        "        dim_ff = DIM_FF,\n",
        "        dropout = DROPOUT\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
        "    criterion = nn.TripletMarginLoss(margin = 1.0, p = 2)\n",
        "\n",
        "    # training loop\n",
        "    print(\"\\nStarting Training...\")\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        total_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "            q_ids, p_ids, n_ids = batch['q_ids'], batch['p_ids'], batch['n_ids']\n",
        "            q_mask, p_mask, n_mask = batch['q_mask'], batch['p_mask'], batch['n_mask']\n",
        "\n",
        "            q_emb = model(q_ids, q_mask)\n",
        "            p_emb = model(p_ids, p_mask)\n",
        "            n_emb = model(n_ids, n_mask)\n",
        "\n",
        "            loss = criterion(q_emb, p_emb, n_emb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            batch_count += 1\n",
        "\n",
        "            if batch_count % 100 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Batch {batch_count}/{len(train_dataloader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = total_loss / batch_count\n",
        "        print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % SAVE_EVERY_EPOCH == 0:\n",
        "            save_path = os.path.join(CHECKPOINT_DIR, f\"model_epoch_{epoch+1}.pt\")\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "            }, save_path)\n",
        "\n",
        "            print(f\"Saved checkpoint: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq2eplFGNrAA"
      },
      "source": [
        "## Inferencing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAX8Mga7CkdW",
        "outputId": "6145ce45-332d-44b3-93db-a6504c28cebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating document embeddings...\n",
            "--------------------------------------------------\n",
            "Starting Semantic Search...\n",
            "--------------------------------------------------\n",
            "\n",
            "Query: 'cystic mass on uterus symptoms'\n",
            "   Rank 1: Score 0.4981 | Doc ID 0\n",
            "   -> The patient presented to the emergency room with severe abdominal pain in the left lower quadrant, which was diagnosed as a cystic mass on the left anterior wall of the uterus. Presenting Symptoms: Severe abdominal pain in the left lower quadrant...\n",
            "   Rank 2: Score 0.1999 | Doc ID 1\n",
            "   -> The patient presented to the emergency department with a high-grade fever, myalgia, and headache....\n",
            "   Rank 3: Score 0.0971 | Doc ID 2\n",
            "   -> He received induction chemotherapy with daunorubicin and cytarabine (3+7), and during his hospital course, he developed febrile neutropenia but eventually resolved on Day 21....\n",
            "\n",
            "Query: 'dengue fever symptoms'\n",
            "   Rank 1: Score 0.5865 | Doc ID 1\n",
            "   -> The patient presented to the emergency department with a high-grade fever, myalgia, and headache....\n",
            "   Rank 2: Score 0.2797 | Doc ID 0\n",
            "   -> The patient presented to the emergency room with severe abdominal pain in the left lower quadrant, which was diagnosed as a cystic mass on the left anterior wall of the uterus. Presenting Symptoms: Severe abdominal pain in the left lower quadrant...\n",
            "   Rank 3: Score 0.0449 | Doc ID 2\n",
            "   -> He received induction chemotherapy with daunorubicin and cytarabine (3+7), and during his hospital course, he developed febrile neutropenia but eventually resolved on Day 21....\n",
            "\n",
            "Query: 'AML M-4 treatment options'\n",
            "   Rank 1: Score 0.4237 | Doc ID 2\n",
            "   -> He received induction chemotherapy with daunorubicin and cytarabine (3+7), and during his hospital course, he developed febrile neutropenia but eventually resolved on Day 21....\n",
            "   Rank 2: Score -0.1312 | Doc ID 0\n",
            "   -> The patient presented to the emergency room with severe abdominal pain in the left lower quadrant, which was diagnosed as a cystic mass on the left anterior wall of the uterus. Presenting Symptoms: Severe abdominal pain in the left lower quadrant...\n",
            "   Rank 3: Score -0.1348 | Doc ID 1\n",
            "   -> The patient presented to the emergency department with a high-grade fever, myalgia, and headache....\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/MedEmbed_Checkpoints\"\n",
        "tokenizer = Tokenizer.from_file(f\"{checkpoint_dir}/tokenizer.json\")\n",
        "\n",
        "model = SentenceEmbeddingModel(\n",
        "    vocab_size=tokenizer.get_vocab_size(),\n",
        "    d_model=256,\n",
        "    nhead=4,\n",
        "    num_layers=4,\n",
        "    dim_ff=1024,\n",
        "    max_seq_len=128\n",
        ")\n",
        "\n",
        "checkpoint = torch.load(f\"{checkpoint_dir}/model_epoch_10.pt\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# generate embedding\n",
        "def get_embedding(text):\n",
        "    enc = tokenizer.encode(text)\n",
        "    ids = torch.tensor(enc.ids).unsqueeze(0)\n",
        "    mask = torch.tensor(enc.attention_mask).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        embedding = model(ids, mask)\n",
        "        return F.normalize(embedding, p = 2, dim = 1)\n",
        "\n",
        "\n",
        "docs = [\n",
        "    \"The patient presented to the emergency room with severe abdominal pain in the left lower quadrant, which was diagnosed as a cystic mass on the left anterior wall of the uterus. Presenting Symptoms: Severe abdominal pain in the left lower quadrant\",\n",
        "    \"The patient presented to the emergency department with a high-grade fever, myalgia, and headache.\",\n",
        "    \"He received induction chemotherapy with daunorubicin and cytarabine (3+7), and during his hospital course, he developed febrile neutropenia but eventually resolved on Day 21.\"\n",
        "    ]\n",
        "\n",
        "queries = [\n",
        "    \"cystic mass on uterus symptoms\",\n",
        "    \"dengue fever symptoms\",\n",
        "    \"AML M-4 treatment options\"\n",
        "]\n",
        "\n",
        "print(\"\\nGenerating document embeddings...\")\n",
        "# Pre-calculate and stack all doc vectors into one matrix [N_docs, Dim]\n",
        "docs_embeddings = torch.cat([get_embedding(doc) for doc in docs], dim = 0)\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Starting Semantic Search...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for query_text in queries:\n",
        "    print(f\"\\nQuery: '{query_text}'\")\n",
        "\n",
        "    # 1. Get query vector [1, Dim]\n",
        "    query_vec = get_embedding(query_text)\n",
        "\n",
        "    # 2. Calculate Cosine Similarity against all docs\n",
        "    # Since vectors are normalized, this is just matrix multiplication.\n",
        "    # [1, Dim] x [Dim, N_docs] -> [1, N_docs]\n",
        "    scores = torch.mm(query_vec, docs_embeddings.transpose(0, 1))\n",
        "\n",
        "    # 3. Sort results by score (descending)\n",
        "    # Get top N results (e.g., top 2)\n",
        "    top_k_scores, top_k_indices = torch.topk(scores[0], k = len(docs))\n",
        "\n",
        "    # 4. Print Results\n",
        "    for i, (score, idx) in enumerate(zip(top_k_scores, top_k_indices)):\n",
        "        doc_idx = idx.item()\n",
        "        print(f\"   Rank {i+1}: Score {score.item():.4f} | Doc ID {doc_idx}\")\n",
        "        # Print the first 100 chars of the doc for context\n",
        "        print(f\"   -> {docs[doc_idx]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kUWgL8bTcr2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05b720f0b4cb437692bd1037d49d64ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1bffe46513f475799f1ba7bcaf9eda2",
              "IPY_MODEL_7b1ee7f53fe34a6f90a393e07b26f4db",
              "IPY_MODEL_edaa01161ac443e88336597703749ea0"
            ],
            "layout": "IPY_MODEL_8eacf44157904aadb53e23de1911f20d"
          }
        },
        "07b08486debb4224a58fd4bc2d2d8777": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10b2d9596d264790a32c08e748dc2919": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10ec6aa6471345e5bb86ac7a3e8a0e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1a5c052bd1343f7a2854c18367adeb5",
            "placeholder": "",
            "style": "IPY_MODEL_10b2d9596d264790a32c08e748dc2919",
            "value": "232684/232684[00:00&lt;00:00,407480.17examples/s]"
          }
        },
        "22cd7da3525446d5a9ccef223166e753": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e33c20ee3ee346448fb876508eba8fa8",
              "IPY_MODEL_e51fa89532b146bda7861612c1feaee2",
              "IPY_MODEL_32e8011a72e64cae85f5a80b0c594798"
            ],
            "layout": "IPY_MODEL_c0303b5baa334815ad0a59bff5e4544e"
          }
        },
        "2652bac33bac494c8671488af2dcb7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d137ccf33044bd6b97e1cb8765dfca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e8011a72e64cae85f5a80b0c594798": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67fb286a59f843be8c839315761d9e49",
            "placeholder": "",
            "style": "IPY_MODEL_ca8061a431244951af3d9e52455ed145",
            "value": "59.7M/59.7M[00:02&lt;00:00,23.3MB/s]"
          }
        },
        "39fa7924f63d464189f02ac7b2793bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67fb286a59f843be8c839315761d9e49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734f461af3cc4d95b3dd491111cd3ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b6543f5a8442208e2ee69ba0d34260": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b1ee7f53fe34a6f90a393e07b26f4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96eca56e290245c39c840ccc854295fe",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2652bac33bac494c8671488af2dcb7dd",
            "value": 1
          }
        },
        "836704d504f74434bd003b40166b6c10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86755138798c430f98d49d5abe71d065": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eacf44157904aadb53e23de1911f20d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eb4ce9559a44aecab8c0b0ac31d8511": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d81272e4daf748ccaad0b73f642aad33",
              "IPY_MODEL_9eb8d69001a34a4ea74e13d983b6e04e",
              "IPY_MODEL_10ec6aa6471345e5bb86ac7a3e8a0e40"
            ],
            "layout": "IPY_MODEL_734f461af3cc4d95b3dd491111cd3ea9"
          }
        },
        "931fc409105c44b29cb900121279f204": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95870392877641499557ed6ed6b15b38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96eca56e290245c39c840ccc854295fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9eb8d69001a34a4ea74e13d983b6e04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_836704d504f74434bd003b40166b6c10",
            "max": 232684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9584619bb5c42ebb0b77b067a89fb5a",
            "value": 232684
          }
        },
        "b1a5c052bd1343f7a2854c18367adeb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6ee53b11c81485ca9216be7b1ebd141": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0303b5baa334815ad0a59bff5e4544e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1bffe46513f475799f1ba7bcaf9eda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95870392877641499557ed6ed6b15b38",
            "placeholder": "",
            "style": "IPY_MODEL_07b08486debb4224a58fd4bc2d2d8777",
            "value": "README.md:"
          }
        },
        "ca8061a431244951af3d9e52455ed145": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee3811f7d4e4282afc68a5f59a14b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d81272e4daf748ccaad0b73f642aad33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee3811f7d4e4282afc68a5f59a14b1b",
            "placeholder": "",
            "style": "IPY_MODEL_39fa7924f63d464189f02ac7b2793bc1",
            "value": "Generatingtrainsplit:100%"
          }
        },
        "d8618e2aa66f4487b135326dbf77b0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e33c20ee3ee346448fb876508eba8fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_931fc409105c44b29cb900121279f204",
            "placeholder": "",
            "style": "IPY_MODEL_74b6543f5a8442208e2ee69ba0d34260",
            "value": "data/train-00000-of-00001.parquet:100%"
          }
        },
        "e51fa89532b146bda7861612c1feaee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d137ccf33044bd6b97e1cb8765dfca2",
            "max": 59662147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86755138798c430f98d49d5abe71d065",
            "value": 59662147
          }
        },
        "edaa01161ac443e88336597703749ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6ee53b11c81485ca9216be7b1ebd141",
            "placeholder": "",
            "style": "IPY_MODEL_d8618e2aa66f4487b135326dbf77b0bd",
            "value": "6.36k/?[00:00&lt;00:00,331kB/s]"
          }
        },
        "f9584619bb5c42ebb0b77b067a89fb5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
